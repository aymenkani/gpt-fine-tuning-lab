# GPT Fine-Tuning Lab

This project demonstrates fine-tuning of GPT models using **PyTorch** and **Hugging Face Transformers**.  
The notebook walks through dataset preparation, model training, evaluation, and pushing the fine-tuned model to the Hugging Face Hub.

## Contents
- `gpt_fine-tuning-with-pytorch_and_transformers__plus_descriptions.ipynb`: Jupyter notebook with code and explanations.
- `requirements.txt`: Dependencies for running the notebook.

## Trained Model
The fine-tuned model is available on my Hugging Face profile:  
ðŸ‘‰ [Hugging Face Model](https://huggingface.co/AymenELKani/codeReasoningGPT-v2)


## âš¡ Quick Usage
You can load and test the model directly from Hugging Face:

```python
from transformers import pipeline

# Load the fine-tuned model from Hugging Face Hub
pipe = pipeline("text-generation", model="your-username/your-model-name")

# Example: generate Python code
print(pipe("Write a Python function that prints prime numbers:")[0]["generated_text"])
